{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a3ae3d2",
   "metadata": {},
   "source": [
    "Data location: https://kingcounty.gov/en/dept/metro/rider-tools/mobile-and-web-apps#toc-developer-resources"
   ]
  },
  {
   "cell_type": "code",
   "id": "6f0f71d8",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mpldates\n",
    "import seaborn as sns\n",
    "import plotly as py\n",
    "from numpy.lib.recfunctions import drop_fields"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da529e1e",
   "metadata": {},
   "source": [
    "#solve the 'fuzzy text' issue by increasing the DPI with a whole format change (from Matplotlib)\n",
    "%config InlineBackend.figure_format='retina'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6956f535",
   "metadata": {},
   "source": [
    "# Import all CSVs\n",
    "GTFS_path_location = \"King_County_GTFS_feed/\"\n",
    "\n",
    "agency = pd.read_csv(GTFS_path_location + \"agency.txt\")\n",
    "calendar = pd.read_csv(GTFS_path_location + \"calendar.txt\")\n",
    "calendar_dates = pd.read_csv(GTFS_path_location + \"calendar_dates.txt\")\n",
    "fare_attributes = pd.read_csv(GTFS_path_location + \"fare_attributes.txt\")\n",
    "fare_rules = pd.read_csv(GTFS_path_location + \"fare_rules.txt\")\n",
    "routes = pd.read_csv(GTFS_path_location + \"routes.txt\")\n",
    "shapes = pd.read_csv(GTFS_path_location + \"shapes.txt\")\n",
    "stop_times = pd.read_csv(GTFS_path_location + \"stop_times.txt\")\n",
    "stops = pd.read_csv(GTFS_path_location + \"stops.txt\")\n",
    "trips = pd.read_csv(GTFS_path_location + \"trips.txt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7af40c7c",
   "metadata": {},
   "source": [
    "### Treatment\n",
    "#### convert numbers to datetime"
   ]
  },
  {
   "cell_type": "code",
   "id": "d1a3ce87",
   "metadata": {},
   "source": [
    "calendar[\"start_date\"] = pd.to_datetime(calendar[\"start_date\"], format = \"%Y%m%d\")\n",
    "calendar[\"end_date\"] = pd.to_datetime(calendar[\"end_date\"], format = \"%Y%m%d\")\n",
    "calendar_dates[\"date\"] = pd.to_datetime(calendar_dates[\"date\"], format = \"%Y%m%d\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "903b18e2",
   "metadata": {},
   "source": [
    "### Combine both Calendar dataframes"
   ]
  },
  {
   "cell_type": "code",
   "id": "b5df6e2a",
   "metadata": {},
   "source": [
    "# Map column values from integer to date-time\n",
    "# build dataframe calendar_full\n",
    "#    index = all service_id (outer join of both service_id sets)\n",
    "#    column = all dates in range (min start date, max end date)\n",
    "#    True/False or 1/0 if service is given\n",
    "# fill in calendar values\n",
    "# fill in calendar_date values\n",
    "\n",
    "# collapse down to weekdays (percent of day X has service)\n",
    "\n",
    "# heatmap of calendar_full\n",
    "# heatmap of calendar_week\n",
    "# set dataframe calendar_week as booleans"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "837e6302-d9f7-42b4-a7ad-20f0329e15a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "def create_calendar_full (calendar, calendar_dates):\n",
    "    \"\"\"\n",
    "    creates a dataframe with:\n",
    "    Columns:\n",
    "        [0] service_id\n",
    "        [1:-1] date-time objects, each date from earliest date to latest date in Calendar\n",
    "    Index:\n",
    "        integers from 0\n",
    "    Values:\n",
    "        - service ID is filled with all unique values from calendar and calendar_dates\n",
    "        - all other values are NaN\n",
    "    \n",
    "    \"\"\"\n",
    "    # Create variable calendar_full_columns\n",
    "    # Is a series with every date (in date time) from the first date available in calendar to the last\n",
    "    # Calendar should have the full range of dates covered by the database\n",
    "    cal_range_max = calendar.loc[:,[\"start_date\",\"end_date\"]].max().max()\n",
    "    cal_range_min = calendar.loc[:,[\"start_date\",\"end_date\"]].min().min()\n",
    "    cal_range = pd.date_range(start = cal_range_min, end = cal_range_max, inclusive=\"both\")\n",
    "    calendar_full_columns = pd.Series([\"service_id\"] + list(cal_range))\n",
    "\n",
    "    # Create variable service_id_list\n",
    "    # Is a series with every service id in calendar and calendar_dates\n",
    "    # filtered for only unique \n",
    "    service_id_list = pd.merge(calendar.loc[:,[\"service_id\"]], calendar_dates.loc[:,[\"service_id\"]], how = \"outer\")\n",
    "    service_id_list.drop_duplicates(inplace = True)\n",
    "    service_id_list.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    # Create dataframe\n",
    "    calendar_full = pd.DataFrame(data = service_id_list, columns = calendar_full_columns)\n",
    "    \n",
    "    return calendar_full\n",
    "\n",
    "\n",
    "def add_calendar (calendar_full, calendar):\n",
    "    \"\"\"\n",
    "    assumes calendar_full's index is intergers indexed by 1\n",
    "    assumes calendar_full's columns are as such:\n",
    "      [0] service_id\n",
    "      [1:-1] date-time objects\n",
    "    \n",
    "    \"\"\"\n",
    "    # iterate through entire calendar_full, sans service_id column\n",
    "    # where i is index number, and j is column number\n",
    "    for i in range(0,calendar_full.index.max() + 1):\n",
    "        for j in range(1,len(calendar_full.columns)):\n",
    "            # Target in Calendar, based on numerical index/column of calendar_full\n",
    "            target_cal_index = calendar[\"service_id\"] == calendar_full[\"service_id\"][i]\n",
    "            target_cal_column = calendar_full.columns[j].day_name().lower()\n",
    "            calendar_full.iloc[i,j] = calendar.loc[target_cal_index, target_cal_column]\n",
    "   \n",
    "    return calendar_full\n",
    "\n",
    "def add_calendar_dates (calendar_full, calendar_dates):\n",
    "    \"\"\"\n",
    "    assumes calendar_full's index is intergers indexed by 1\n",
    "    assumes calendar_full's columns are as such:\n",
    "      [0] service_id\n",
    "      [1:-1] date-time objects\n",
    "    \n",
    "    assumes calendar_dates only has unique combinations or service_id + date.\n",
    "    this function will ignore non-unique combinations\n",
    "    \n",
    "    \"\"\"\n",
    "    # iterate through entire calendar_full, sans service_id column\n",
    "    # where i is index number, and j is column number\n",
    "    for i in range(0,calendar_full.index.max() + 1):\n",
    "        for j in range(1,len(calendar_full.columns)):\n",
    "            # find index in calendar_dates that matches a particular cell in calendar_full\n",
    "            # target index is a series of booleans\n",
    "            target_service_id = calendar_dates[\"service_id\"] == calendar_full.iloc[i,0]\n",
    "            target_date = calendar_dates[\"date\"] == calendar_full.columns[j]\n",
    "            target_index = target_service_id & target_date\n",
    "            # check to make sure there is a target (target_index has one True value)\n",
    "            if target_index.sum() == 1:\n",
    "                # exception is value of exception type (as per data dictionary, is only 1 or 2)\n",
    "                exception = calendar_dates.loc[target_index, \"exception_type\"].iloc[0]\n",
    "                if exception == 1:\n",
    "                    # service added\n",
    "                    calendar_full.iloc[i,j] = 1        \n",
    "                elif exception == 2:\n",
    "                    # service removed\n",
    "                    calendar_full.iloc[i,j] = 0\n",
    "    return calendar_full\n",
    "\n",
    "\n",
    "def cal_full_alter_axis(x):\n",
    "    \"\"\"\n",
    "    Pull service id out of the columns and use it as the index\n",
    "    \"\"\"\n",
    "    x = x.set_index(\"service_id\").copy()\n",
    "    return x\n",
    "\n",
    "def create_calendar_week(calendar_full,binary = False):\n",
    "    \"\"\"\n",
    "    create DF calendar_week.\n",
    "    It's in the same format as \"calendar\"\n",
    "    values are averages\n",
    "    \n",
    "    If binary is True a field of binary values are returned.  \n",
    "    Where the values are the averages round to 0 or 1\n",
    "    \"\"\"\n",
    "    calendar_week = pd.DataFrame(data = calendar_full[\"service_id\"], \n",
    "                                 columns = [\"service_id\"]\n",
    "                                )\n",
    "\n",
    "    weekday_list = [\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"sunday\"]\n",
    "\n",
    "    for day in weekday_list:\n",
    "        # And then add the two edge dates\n",
    "        filter_values = [True] + [True if x == day else False for x in calendar_full.columns[1:]]\n",
    "        # create DF of serviceid plus only days of specified week\n",
    "        filtered_cal = calendar_full.loc[:,filter_values]\n",
    "        #average day of week\n",
    "        add_day = filtered_cal.iloc[:,1:].T.groupby(lambda x: True).mean().T\n",
    "        if binary == True:\n",
    "            add_day = add_day.map(lambda x: round(x))\n",
    "        add_day.columns = [day]\n",
    "        calendar_week[day] = add_day\n",
    "\n",
    "    calendar_week[\"start_date\"] = [calendar_full.columns[1]] * calendar_week.shape[0]\n",
    "    calendar_week[\"end_date\"] = [calendar_full.columns[-1]] * calendar_week.shape[0]\n",
    "\n",
    "    return calendar_week"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "679d39dd",
   "metadata": {},
   "source": [
    "# create calendar_full and populate it\n",
    "calendar_full = create_calendar_full(calendar, calendar_dates)\n",
    "calendar_full = calendar_full.pipe(add_calendar, calendar = calendar) \\\n",
    "    .pipe(add_calendar_dates, calendar_dates = calendar_dates)\n",
    "# create an alternate version for graphing and analysis\n",
    "cal_full_alt = cal_full_alter_axis(calendar_full)\n",
    "# Create calendar week\n",
    "calendar_week = create_calendar_week(calendar_full, binary = True)\n",
    "calendar_week_mean = create_calendar_week(calendar_full, binary = False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cee1746e",
   "metadata": {},
   "source": [
    "sns.set_context('paper')\n",
    "sns.color_palette('blend:#3e6e64,#c3d4d0', as_cmap = True)\n",
    "ax = (sns.heatmap(calendar_week_mean.set_index(\"service_id\").iloc[:,:-2], \n",
    "            yticklabels = True, \n",
    "            cbar = False, \n",
    "            cmap = sns.color_palette('blend:#cfd8d6,#3e6e64', as_cmap = True), \n",
    "            linewidth = 0.5\n",
    "           )\n",
    "    )\n",
    "ax.set(xlabel = \"Weekday\",\n",
    "      ylabel = \"Service ID\",\n",
    "      title = \"Heatmap: Likelyhood of Service\"\n",
    "     )\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6ed2020d",
   "metadata": {},
   "source": [
    "# Order service ids by how many trips they are assigned to, in descending order.\n",
    "# service ids with no trips are appended to the end\n",
    "x = pd.Index(set(cal_full_alt.index).difference(set(trips.index)))\n",
    "x = trips.value_counts(\"service_id\").index.append(x)\n",
    "cal_full_alt_graph = cal_full_alt.reindex(x, copy = True)\n",
    "\n",
    "# change timestamps in column axis to strings for visualization\n",
    "cal_full_alt_graph.columns = [y.strftime(\"%b-%d\") for y in cal_full_alt.columns]\n",
    "\n",
    "\n",
    "\n",
    "sns.set_context('paper')\n",
    "sns.color_palette('blend:#3e6e64,#c3d4d0', as_cmap = True)\n",
    "ax = (sns.heatmap(cal_full_alt_graph.iloc[:,0:31], \n",
    "            yticklabels = True, \n",
    "            cbar = False, \n",
    "            cmap = sns.color_palette('blend:#cfd8d6,#3e6e64', as_cmap = True), \n",
    "            linewidth = 0.5\n",
    "           )\n",
    "    )\n",
    "ax.set(xlabel = \"Date\",\n",
    "      ylabel = \"Service ID\",\n",
    "      title = \"Service heatmap\"\n",
    "     )\n",
    "\n",
    "#ax.xaxis.set_major_formatter(mpldates.DateFormatter(\"%d-%b\")) doesnt work yet, moving on\n",
    "xtix = ax.get_xticks()\n",
    "ax.set_xticks(xtix[::7])\n",
    "ax.set_xticklabels(cal_full_alt_graph.iloc[:,0:31].columns[::7])\n",
    "ax.tick_params(axis = 'x', rotation = 0)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c5f87b08",
   "metadata": {},
   "source": [
    "# I have a map of the average service_ids for any given weekday (or specific day)\n",
    "# For any given route and day, find all the trips.\n",
    "# next lets get the start time for all of them"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e8bddd2d",
   "metadata": {},
   "source": [
    "\n",
    "#attach routes to trips on route_id for route_names\n",
    "\n",
    "#combine stop_times to trips on trip_id tring to pull the first arrival_time\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9af5ec8f",
   "metadata": {},
   "source": [
    "def trips_merged(trips, stop_times, routes, calendar_week):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    #pull stop times\n",
    "    stop_times[\"index_og\"] = stop_times.index\n",
    "    stop_times_index = stop_times.groupby([\"trip_id\"])[[\"arrival_time\",\"index_og\"]].min(\"arrival_time\")[\"index_og\"]\n",
    "    trip_times = stop_times.loc[index1,[\"trip_id\",\"arrival_time\"]]\n",
    "\n",
    "    #pull route names\n",
    "    trip_routes = routes.loc[:,[\"route_id\",\"route_short_name\",\"route_desc\"]]\n",
    "    \n",
    "    #pull service_weekdays\n",
    "    # just drop it in\n",
    "    \n",
    "    trips_alt = pd.merge(left = trips, right = trip_times, how = \"inner\", on = \"trip_id\")\n",
    "    \n",
    "    trips_alt = pd.merge(left = trips_alt, right = trip_routes, how = \"inner\", on = \"route_id\")\n",
    "    \n",
    "    trips_alt = pd.merge(left = trips_alt, right = calendar_week, how = \"inner\", on = \"service_id\")\n",
    "\n",
    "    return trips_alt\n",
    "    \n",
    "def routes_on_a_day(trips, weekday, route,direction):\n",
    "    return trips.loc[((trips[\"route_short_name\"] == route) & \n",
    "                      (trips[weekday] == 1) & \\\n",
    "                      (trips[\"direction_id\"] == direction)),\n",
    "                     :].sort_values(\"arrival_time\")\n",
    "    \n",
    "def stop_time_to_datetime(value):\n",
    "    time = value\n",
    "    hour = int(time[0:2])\n",
    "    if hour > 23:\n",
    "        day = \"1970-01-02\"\n",
    "        hour = hour - 24\n",
    "        time = str(hour) + time[2:-1]\n",
    "    else:\n",
    "        day = \"1970-01-01\"\n",
    "    return pd.to_datetime((day + \" \" + time))\n",
    "\n",
    "def create_time_delta(df, time_col, delta_col):\n",
    "    \"\"\"\n",
    "    outputs the same df, with a new column, delt_col\n",
    "    \n",
    "    the timedelta for each point is the time elapsed BEFORE the point.\n",
    "    delta = Tn - T(n-1)\n",
    "    \n",
    "    df: dataframe with the datetime to build from\n",
    "        dataframe the delta time will be added to\n",
    "        \n",
    "    time_col: name of the column with datetime information.\n",
    "              must be in timestamp format\n",
    "              \n",
    "    delta_col: the name of the new column\n",
    "    \"\"\"\n",
    "    # Create a column of the differences\n",
    "    df[delta_col] = df[time_col].diff()\n",
    "    \n",
    "    # create a timedelta object equal to one day \n",
    "    one_day = pd.to_timedelta(1, unit='d')\n",
    "    \n",
    "    # calculate the time differential between the last and the first value.\n",
    "    df.loc[df.index[0],delta_col] = \\\n",
    "                                    df[time_col].iloc[0] - \\\n",
    "                                    (df[time_col].iloc[-1] - one_day)\n",
    "    \n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e0d6588",
   "metadata": {},
   "source": [
    "route_choice = \"D Line\"\n",
    "weekday_choice = \"monday\"\n",
    "direction_choice = 1\n",
    "\n",
    "# merge data desired\n",
    "trips_alt = trips_merged(trips, stop_times, routes, calendar_week)\n",
    "# filter to the desired information\n",
    "route_day = routes_on_a_day(trips_alt, weekday_choice, route_choice, direction_choice)\n",
    "# filter to desired columns\n",
    "route_day = route_day.loc[:,[\"service_id\",\"arrival_time\",\"route_short_name\"]]\n",
    "# Convert 'arrival time' to datetime\n",
    "route_day['arrival_time'] = route_day['arrival_time'].map(stop_time_to_datetime)\n",
    "# create time_delta: difference between arrival times\n",
    "route_day = create_time_delta(route_day, \"arrival_time\", \"time_delta\")\n",
    "route_day.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff4f20e5",
   "metadata": {},
   "source": [
    "# Convert timestamp and deltatime objects to numbers.  Graphing cannot understand datetime objects.\n",
    "route_day[\"delta_val\"] = route_day[\"time_delta\"].map(lambda x: x.seconds/60)\n",
    "route_day[\"time_val\"] = route_day[\"arrival_time\"].map(lambda x: x.hour + x.minute/60)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "ax =(sns.lineplot(data = route_day,\n",
    "                  x = 'time_val',\n",
    "                  y = 'delta_val'\n",
    "                 )\n",
    "    )\n",
    "\n",
    "ax.set(xlabel = \"Hour of the Day\",\n",
    "      ylabel = \"minutes\",\n",
    "      title = \"time between buses - D Line - Weekday - dir 1\"\n",
    "     )\n",
    "\n",
    "#xtix = ax.get_xticks()\n",
    "ax.set_yticks([0,5,10,15,30,45,60])\n",
    "ax.set_ylim(0,65)\n",
    "ax.set_xticks([0,5,7,9,12,16,18,20,21,22,24])\n",
    "ax.set_xlim(0,24)\n",
    "#ax.set_xticklabels(cal_full_alt_graph.iloc[:,0:31].columns[::7])\n",
    "#ax.tick_params(axis = 'x', rotation = 0)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e58de80c",
   "metadata": {},
   "source": [
    "# Make the graph prettier\n",
    "# try to make it really compact (so it can go beside a map)\n",
    "# smooth it out into something usable for riders\n",
    "\n",
    "\n",
    "# things to look further into: does the number of stops change for a route?\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6818ae52",
   "metadata": {},
   "source": [
    "# Graph multiple routes on the same axis\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
